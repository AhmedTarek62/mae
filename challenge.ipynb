{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 35px;\">**Waves Lab - Foundation Model Challange!**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the **üì°Radio Foundation Model** Challenge Notebook! \n",
    "\n",
    "This notebook is designed to guide you through the process of adapting our foundational model for various radio tasks. Our model is a Masked Autoencoder (MAE) tailored for radio signal processing built on the vision transformer architecture.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "The primary goal of this challenge is to leverage our model's capabilities to address diverse tasks within the wireless communications domain. Participants are encouraged to fine-tune and adapt the model for applications such as:\n",
    "\n",
    "- ***Signal Classification:*** Identifying different types of radio signals.\n",
    "- ***Channel Estimation:*** Predicting the state of communication channels.\n",
    "- ***Spectrum Sensing:*** Detecting the presence of signals in a frequency band.\n",
    "- ***Signal Reconstruction:*** Reconstructing signals from incomplete or corrupted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Setup Required**\n",
    "\n",
    "Before running this notebook, please ensure you have configured the necessary parameters in a `.yaml` file similar to `configs/template.yaml` example. This file allows you to define key settings for the fine-tuning experiment, including:\n",
    "\n",
    "- **Base Model**: Specify the path to the pre-trained model and the desired architecture (`model_path`, `model_arch`).\n",
    "- **Task-Specific Parameters**: Set the number of classes, input data size, and any additional model-specific configurations (`num_classes`, `input_size`).\n",
    "- **Dataset Information**: Provide the path to your dataset (`data_path`).\n",
    "- **Training Hyperparameters**: Adjust batch size, learning rate, number of epochs, and more (`batch_size`, `lr`, `epochs`).\n",
    "- **Optimizer and Regularization**: Define weight decay, learning rate scheduling, and drop path rate (`weight_decay`, `blr`, `drop_path`).\n",
    "- **Device and Environment**: Set the device type (`cuda` or `cpu`), random seed, and data loader options (`device`, `seed`, `num_workers`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî Before proceeding with the setup, you'll need to define some key parameters for your fine-tuning experiment. Please make sure to configure the following variables:\n",
    "\n",
    "1. **base_model_arch**:  \n",
    "   Choose the pre-trained model architecture you'd like to fine-tune. The available options are:\n",
    "   - `vit_small_patch16`\n",
    "   - `vit_medium_patch16`\n",
    "   - `vit_large_patch16`\n",
    "\n",
    "2. **base_model_path**:  \n",
    "   Provide the path to the selected pre-trained model architecture on your system.\n",
    "\n",
    "3. **task**:  \n",
    "   Select the task you want to fine-tune the base model for. The available tasks are:\n",
    "   - `Segmentation`\n",
    "   - `CSI Sensing`\n",
    "   - `Signal Identification`\n",
    "   - `Positioning`\n",
    "   - `Channel Estimation`\n",
    "   - `Custom` (for your own dataset and custom processing functions)\n",
    "\n",
    "4. **data_path**:  \n",
    "   Specify the path to the dataset on your system for the chosen task. This should be the dataset required for your fine-tuning.\n",
    "   \n",
    "Once you have configured these parameters, set the `config_path` variable in the next cell with the path of that `.yaml` file to proceed with running the notebook.\n",
    "\n",
    "**üìù Edit the `.yaml` file now!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config_path = \"/home/elsayedmohammed/mae/configs/segmentation.yaml\"    # TODO: Set\n",
    "\n",
    "with open(config_path, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset path provided: /home/elsayedmohammed/datasets/segmentation_dataset\n",
      "The outputs path provided: /home/elsayedmohammed/outputs/8jan_segmentation\n",
      "==== Loading all the configs..\n",
      "Finetuning on the (segmentation) task..\n",
      "==== Setting the device and random seed..\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from FineTuningArgs import FineTuningArgs\n",
    "\n",
    "exp_name = config[\"experiment_name\"]\n",
    "del config[\"experiment_name\"]\n",
    "\n",
    "data_path = config[\"data_path\"]\n",
    "assert os.path.isdir(data_path), print(f\"Incorrect data_path! ({data_path})\")\n",
    "print(f\"The dataset path provided: {data_path}\")\n",
    "\n",
    "output_dir = os.path.join(config[\"output_dir\"], exp_name)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"The outputs path provided: {output_dir}\")\n",
    "\n",
    "print(f\"==== Loading all the configs..\")\n",
    "config = FineTuningArgs(**config)\n",
    "\n",
    "print(f\"==== Setting the device and random seed..\")\n",
    "device = torch.device(config.device)\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "\n",
    "cudnn.benchmark = True # DEVELOPERS:check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.task == 'segmentation':\n",
    "    from dataset_classes.segmentation_dataset import SegmentationDataset as TaskDataset\n",
    "elif config.task == 'sensing':\n",
    "    from dataset_classes.csi_sensing_dataset import CSISensingDataset as TaskDataset\n",
    "elif config.task == 'signal_identification':\n",
    "    from dataset_classes.radio_signal_identification_dataset import SignalIdentificatio_Dataset as TaskDataset\n",
    "elif config.task == 'positioning':\n",
    "    from dataset_classes.positioning_nr_dataset import PositioningNR as TaskDataset\n",
    "elif config.task == 'channel_estimation':\n",
    "    from dataset_classes.ofdm_channel_estimation_dataset import OfdmChannelEstimation as TaskDataset\n",
    "else:\n",
    "    # TODO\n",
    "    assert False, print(\"Replace this line with import statment \\\n",
    "                         for your dataset class as TasDataset\")\n",
    "    # You can also build your dataset class here in this cell and then change the two following lines accordingly\n",
    "\n",
    "dataset_train = TaskDataset(data_path, split=\"train\")\n",
    "dataset_val = TaskDataset(data_path, split=\"val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into Train and Val objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training dataset\n",
    "## 1. Create the sampling object (Training)\n",
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "## 2. Create the dataloader (Training)\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, sampler=sampler_train,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "# For Valdiation dataset\n",
    "## 1. Create the sampling object (Validation)\n",
    "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "## 2. Create the dataloader (Validation)\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val, sampler=sampler_val,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=config.pin_mem,\n",
    "        drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elsayedmohammed/AoA-Pruning/pruning-venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained checkpoint from: /home/elsayedmohammed/vit-models/pretrained_small_75.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elsayedmohammed/mae/models/segmentation.py:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['decoder_pred.weight', 'decoder_pred.bias'], unexpected_keys=['decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_blocks.4.norm1.weight', 'decoder_blocks.4.norm1.bias', 'decoder_blocks.4.attn.qkv.weight', 'decoder_blocks.4.attn.qkv.bias', 'decoder_blocks.4.attn.proj.weight', 'decoder_blocks.4.attn.proj.bias', 'decoder_blocks.4.norm2.weight', 'decoder_blocks.4.norm2.bias', 'decoder_blocks.4.mlp.fc1.weight', 'decoder_blocks.4.mlp.fc1.bias', 'decoder_blocks.4.mlp.fc2.weight', 'decoder_blocks.4.mlp.fc2.bias', 'decoder_blocks.5.norm1.weight', 'decoder_blocks.5.norm1.bias', 'decoder_blocks.5.attn.qkv.weight', 'decoder_blocks.5.attn.qkv.bias', 'decoder_blocks.5.attn.proj.weight', 'decoder_blocks.5.attn.proj.bias', 'decoder_blocks.5.norm2.weight', 'decoder_blocks.5.norm2.bias', 'decoder_blocks.5.mlp.fc1.weight', 'decoder_blocks.5.mlp.fc1.bias', 'decoder_blocks.5.mlp.fc2.weight', 'decoder_blocks.5.mlp.fc2.bias', 'decoder_blocks.6.norm1.weight', 'decoder_blocks.6.norm1.bias', 'decoder_blocks.6.attn.qkv.weight', 'decoder_blocks.6.attn.qkv.bias', 'decoder_blocks.6.attn.proj.weight', 'decoder_blocks.6.attn.proj.bias', 'decoder_blocks.6.norm2.weight', 'decoder_blocks.6.norm2.bias', 'decoder_blocks.6.mlp.fc1.weight', 'decoder_blocks.6.mlp.fc1.bias', 'decoder_blocks.6.mlp.fc2.weight', 'decoder_blocks.6.mlp.fc2.bias', 'decoder_blocks.7.norm1.weight', 'decoder_blocks.7.norm1.bias', 'decoder_blocks.7.attn.qkv.weight', 'decoder_blocks.7.attn.qkv.bias', 'decoder_blocks.7.attn.proj.weight', 'decoder_blocks.7.attn.proj.bias', 'decoder_blocks.7.norm2.weight', 'decoder_blocks.7.norm2.bias', 'decoder_blocks.7.mlp.fc1.weight', 'decoder_blocks.7.mlp.fc1.bias', 'decoder_blocks.7.mlp.fc2.weight', 'decoder_blocks.7.mlp.fc2.bias'])\n",
      "Number of params (M): 1.91\n"
     ]
    }
   ],
   "source": [
    "if config.task == 'segmentation':\n",
    "    import models.segmentation as task_model\n",
    "    assert config.base_arch in list(task_model.__dict__.keys()),\\\n",
    "        print(f\"This model architecture ({config.base_arch}) is not available!\")\n",
    "    model = task_model.__dict__[config.base_arch]() \n",
    "\n",
    "elif config.task == 'sensing':\n",
    "    import models.sensing as task_model\n",
    "    assert config.base_arch in list(task_model.__dict__.keys()),\\\n",
    "        print(f\"This model architecture ({config.base_arch}) is not available!\")\n",
    "    model = task_model.__dict__[config.base_arch](global_pool=config.global_pool,\n",
    "                                                num_classes=config.num_classes,\n",
    "                                                drop_path_rate=config.drop_path)\n",
    "    \n",
    "elif config.task == 'signal_identification':\n",
    "    import models.signal_identification as task_model\n",
    "    assert config.base_arch in list(task_model.__dict__.keys()),\\\n",
    "        print(f\"This model architecture ({config.base_arch}) is not available!\")\n",
    "    model = task_model.__dict__[config.base_arch](global_pool=config.global_pool,\n",
    "                                                num_classes=config.num_classes,\n",
    "                                                drop_path_rate=config.drop_path,\n",
    "                                                in_chans=1)\n",
    "elif config.task == 'positioning':\n",
    "    scene = \"outdoor\" # TODO: (DEVELOPERS)\n",
    "    tanh = False # TODO: (DEVELOPERS)\n",
    "    import models.positioning as task_model\n",
    "    assert config.base_arch in list(task_model.__dict__.keys()),\\\n",
    "        print(f\"This model architecture ({config.base_arch}) is not available!\")\n",
    "    model = task_model.__dict__[config.base_arch](global_pool=config.global_pool, num_classes=config.num_classes,\n",
    "                                            drop_path_rate=config.drop_path, tanh=tanh,\n",
    "                                            in_chans=4 if scene == 'outdoor' else 5)\n",
    "elif config.task == 'channel_estimation':\n",
    "    import models.channel_estimation as task_model\n",
    "    assert config.base_arch in list(task_model.__dict__.keys()),\\\n",
    "        print(f\"This model architecture ({config.base_arch}) is not available!\")\n",
    "    model = task_model.__dict__[config.base_arch]() \n",
    "\n",
    "else:\n",
    "    # TODO\n",
    "    assert False, print(\"Replace this line with import statment \\\n",
    "                         for your model class as task_model\")\n",
    "    # You can also build your model class here in this cell and then change the two following lines accordingly\n",
    "    #  \n",
    "# Load the model checkpoint\n",
    "print(f\"Loading pre-trained checkpoint from: {config.base_model_path} ...\")\n",
    "msg = model.load_model_checkpoint(checkpoint_path=config.base_model_path)\n",
    "print(msg) # TODO- (DEVELOPERS): why In_IncompatibleKeys?\n",
    "\n",
    "# Freeze the encoder weights (the base)\n",
    "model.freeze_encoder()\n",
    "model.to(device) \n",
    "\n",
    "# Check the model's number of parameters\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of params (M): %.2f' % (n_parameters / 1.e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion selected: CrossEntropyLoss()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elsayedmohammed/mae/util/misc.py:76: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self._scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# TODO: Feel free to set your own loss function or LR scheduler\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "\n",
    "param_groups = lrd.param_groups_lrd(model, config.weight_decay, layer_decay=config.layer_decay)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=config.lr)\n",
    "loss_scaler = NativeScaler()\n",
    "\n",
    "if config.smoothing > 0.:\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=config.smoothing)\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if config.task in [\"positioning\", \"channel_estimation\"]:\n",
    "    from torch.nn import MSELoss\n",
    "    criterion = MSELoss()\n",
    "\n",
    "print(f\"criterion selected: {str(criterion)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.task == \"segmentation\":\n",
    "    from finetuning_engines.segmentation import train_one_epoch, evaluate\n",
    "elif config.task in [\"sensing\", \"signal_identification\"]:\n",
    "    from finetuning_engines.sensing import train_one_epoch, evaluate\n",
    "elif config.task == \"positioning\":\n",
    "    from finetuning_engines.positioning import train_one_epoch, evaluate\n",
    "elif config.task == \"channel_estimation\":\n",
    "    from finetuning_engines.channel_estimation import train_one_epoch, evaluate\n",
    "else:\n",
    "    # TODO\n",
    "    assert False, print(\"Replace this line with import statment \\\n",
    "                         for your finetuing engine script with train_one_epoch and evaluate functions\")\n",
    "    # You can also build your functions here in this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 epochs..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:05<00:00,  2.61batch/s, loss=1.15]\n",
      "Validation..: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:04<00:00,  5.26batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0:00:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import util.misc as misc\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "config.epochs = 1\n",
    "print(f\"Training for {config.epochs} epochs..\")\n",
    "start_time = time.time()\n",
    "least_val_loss, best_stats_epoch = np.inf, 0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    train_stats = train_one_epoch(\n",
    "        model, criterion, data_loader_train,\n",
    "        optimizer, device, epoch, loss_scaler,\n",
    "        config.clip_grad, None,\n",
    "        args=config\n",
    "    )\n",
    "    if config.output_dir and (epoch % config.save_every == 0):\n",
    "        misc.save_model(args=config, output_dir=output_dir, model=model, optimizer=optimizer, loss_scaler=loss_scaler, epoch=epoch)\n",
    "\n",
    "    val_stats = evaluate(data_loader_val, model, criterion, device)\n",
    "    if val_stats[\"avg_loss\"] < least_val_loss:\n",
    "         least_val_loss = val_stats[\"avg_loss\"]\n",
    "         best_stats_epoch = epoch\n",
    "\n",
    "    if config.output_dir:\n",
    "        log_stats = {\"epoch\": epoch,\n",
    "                     \"train_loss\": train_stats[\"avg_loss\"],\n",
    "                     \"val_loss\": val_stats[\"avg_loss\"],\n",
    "                     \"val_acc\": val_stats[\"avg_acc\"]}\n",
    "        with open(os.path.join(output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to report the finetuning results in the following `.txt` format to enable evaluation.\n",
    "\n",
    "Our evaluation takes into account:\n",
    " - Number of data samples\n",
    " - Number of model parameters\n",
    " - The reported loss/accuracy\n",
    "\n",
    "**Required Format:**\n",
    "```\n",
    "{\n",
    "    task:               'task_name(arbitrary)',\n",
    "    loss:               validation final loss (if regression) or None otherwise,\n",
    "    accuracy:           validation final accurcay (if classification) or None otherwise,\n",
    "    model_n_parameters: number of model parameters,\n",
    "    validation_length:  number of data samples in your validation dataset\n",
    "    score:              the score assigned to your task (automatically generated)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.misc import report_score\n",
    "\n",
    "report = report_score(config, model, dataset_val, least_val_loss, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"report.json\"), \"w\") as json_file:\n",
    "    json.dump(report, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (DEVELOPERS): Just for us, going to delete this cell soon!\n",
    "\n",
    "validation_length = len(dataset_val)\n",
    "print(f\"validation_length = {validation_length}\")\n",
    "\n",
    "validation_score = min(validation_length // 100 * 10, 100)\n",
    "print(f\"validation_score = {validation_score}\")\n",
    "\n",
    "print(least_val_loss)\n",
    "print(f\"performance (loss) = {least_val_loss}\")\n",
    "\n",
    "perf_score = 100 - least_val_loss*100\n",
    "print(f\"paras_score = {perf_score}\")\n",
    "\n",
    "model_n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"parameteres = {model_n_parameters}\")\n",
    "\n",
    "paras_score = 100 - min(max(model_n_parameters // 200000 * 5, 0), 100) \n",
    "print(f\"paras_score = {paras_score}\")\n",
    "\n",
    "print(f\"===total = {0.5*perf_score + 0.25*paras_score + 0.25*validation_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pruning-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
